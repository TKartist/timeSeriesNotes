# forecasting timeseries data

# Forecasting Procedure
 - Choose a model
 - Split data into train and test sets
 - Fit model on training set
 - Evaluate model on test set
 - Re-fit model on entire data set
 - Forecast for future data

# Section Overview
 - Introduction to Forecasting
 - ACF and PACF plots
 - AutoRegressive - AR
 - Descriptive Statistics and Tests
 - Choosing ARIMA orders
 - ARIMA based models

# Test-Train Split
 - Train Data (larger portion), Test Data (Most recent data)
 - Size of the test set is typically about 20% of the total sample
 - However, the test set's size depends on how long the sample is
   and how far ahead we want to forecast
   The Test set should "IDEALLY" be at least as large as the maximum forecast horizon required.
   Meaning, if we want to predict a month, we need as least a month's worth of data as test set 
 - Longer the forecast horizon, the lower your prediction accuracy becomes

# 3 most common evaluation metrics for regression:
 - Mean Absolute Error (MAE)
 - Mean Squared Error (MSE)
 - Root Mean Squared Error (RMSE)

y - the real value of the test data
predicted(y) - the predicted value from our forecast

MAE: 1 / n * (sum(|y_i - predicted(y_i)|))
 - It is averaging the residuals so it won't alert us if the forecast was really off for a few points
 - We want to be aware of any prediction error that are very large (even few)
 - Solution to this problem is MSE

MSE: 1 / n * sum((y_i - predicted(y_i)) ^ 2)
 - Really punishes the error of the model, so easy to notice even few errors in prediction
 - Problem : the units get squared as well (i.e. we are predicting dollars and the result is dollar squared)
 - Hence, a bit confusing
 - That is why we use RMSE (Most popular)

RMSE: root(MSE)

 - How do we evaluate a forecast for future dates?
    -> It is impossible as we don't know the actual value yet


# Stationarity and Differencing
 - Stationary, if does not exhibit trends and seasonality

# ACF and PACF
 - ACF : AutoCorrelation Function plot
 - PACF : Partial AutoCorrelation Function plot
 - So what is Correlation?
    -> Measure of the strength of the linear relationship between 2 variables
    -> ranges from -1 to +1
    -> Close it is to +1, the stronger the positive linear relationship (upward)
    -> Closer to -1, stronger the negative linear relationship (downward)
    -> Closer to 0, no Correlation (Correlation value 0 means f'(x) = 0)
 - What is AutoCorrelation?
    -> AutoCorrelation Plot shows the correlation of the eries with itself, lagged by 'x' time units
    -> So the y-axis is the correlation and the x-axis is the number of time units of lag
    -> detailed explanation : so how do we get values to plot on Correlagram (AutoCorrelation plot)
       i.e. we are plotting ACF of sales of a store.
       We plot y-axis with "Sales on day i" against x-axis with "Sales on day i - 1", and calculate
       the correlation value (i.e. 0.8). and we repeat this process by increasing alpha of 'i - alpha'
       and finding its correlation value.
       Each of the correlation value will be plotted as y-axis value with "alpha" as the x-axis value.
       This will result in a Correlagram we discussed as ACF.
 - Partial AutoCorrelation?
    -> Instead of directly using the correlation values, we calculate the residuals (the difference
       between the point and the correlation function) and plot that against the next "alpha":
       y-axis: Residuals fitted on day i - alpha, x-axis: sales on day i - alpha - 1

# In conclusion:
 - ACF describes the autocorrelation between an observation and another observation at a
   prior time step that includes direct and indirect dependence information
 - PACF only describes the direct relationship between an observation and its lag.
 - Both are used to choose ORDER PARAMETERS for ARIMA based models.
 